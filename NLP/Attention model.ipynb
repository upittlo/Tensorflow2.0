{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb64f2ce",
   "metadata": {},
   "source": [
    "### This is a template of seq2seq model with attention layer\n",
    "\n",
    "#### Description:\n",
    "\n",
    "- 使用Seq2Seq無掩碼、Seq2Seq基礎模型、Seq2Seq+Attention三種方法\n",
    "- Key concept: Encoder, Decoder\n",
    "\n",
    "\n",
    "Seq2Seq模型實現並不難，但是需要考慮如下幾個細節：\n",
    "\n",
    "- 輸入序列長度不一致如何處理，掩碼屏蔽存在什麼問題\n",
    "- 如何解決RNN模型固有的長期依賴問題\n",
    "- Encoder 和 Decoder 之間傳遞的到底是什麼\n",
    "\n",
    "\n",
    "Ref:https://hk.codetreasures.com/blog/detail/e5rBqs3qAw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375f768",
   "metadata": {},
   "source": [
    "- Sequence pad: 將不同長度句子透過填充  ex: 填充\"\" 將sequence 轉為相同長度\n",
    "\n",
    "\n",
    "- Mask: 填充之後的句子存在大量的無意義字符\"\" 這是我們實際結果不需要的，Mask 功用為告知模型忽略填充字符的影響呢，專注於實際重要的數據, 也能避免loss 計算時被考慮進去\n",
    ">在Keras中只需加入mask_zero = True 即可\n",
    "\n",
    "- Encoder和Decoder之間存在一個context，這個 context 其實是：Encoder最後一個時間步RNN的隱藏層狀態\n",
    "\n",
    "- Teacher forcing:Decoder 在訓練過程中引入先驗知識：將標籤 Y 作為輸入；而推理過程則採用上一個時間步的輸出作為下一個時間步的輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccfa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, optimizers, datasets\n",
    "import os,sys,tqdm\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfcca9",
   "metadata": {},
   "source": [
    "## 1. Create dataset\n",
    "\n",
    "- 隨機生成文字序列, 非正常數據\n",
    "- y1開頭加入 START, y2不加入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae15d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"#\",\"<start>\",'<end>']+list(string.ascii_uppercase)\n",
    "\n",
    "ids = [0,1,2]+[i+3 for i in range(26)]\n",
    "words_to_ids = dict(zip(words,ids))\n",
    "ids_to_words = dict(zip(ids,words))\n",
    "\n",
    "MAX_LEN = 11 # 填充後的序列長度\n",
    "\n",
    "def gen_string():\n",
    "    '''\n",
    "    生成字符串及其倒序\n",
    "    '''\n",
    "    length = np.random.randint(6,11)\n",
    "    x = [np.random.choice(list(string.ascii_uppercase)) for _ in range(length)]\n",
    "    x_reversed = reversed(x)\n",
    "    return list(x),list(x_reversed)\n",
    "\n",
    "\n",
    "def create_dataset(batch_size):\n",
    "    '''\n",
    "    數據集的創建\n",
    "    '''\n",
    "    x,y1,y2 = [],[],[]\n",
    "    for i in range(batch_size):\n",
    "        example = gen_string()\n",
    "        x.append([words_to_ids[c] for c in example[0]])\n",
    "        y1.append([1]+[words_to_ids[c] for c in example[1]])\n",
    "        y2.append([words_to_ids[c] for c in example[1]])  \n",
    "        \n",
    "    x = keras.preprocessing.sequence.pad_sequences(x,maxlen = 10,padding = 'post')\n",
    "    y1 = keras.preprocessing.sequence.pad_sequences(y1,maxlen = MAX_LEN,padding = 'post')\n",
    "    y2 = keras.preprocessing.sequence.pad_sequences(y2,maxlen = MAX_LEN,padding = 'post')\n",
    "    \n",
    "    return x,y1,y2\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc6fae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[28, 27, 23, 14,  9, 18, 27,  3,  0,  0],\n",
       "        [13, 18,  7, 17,  5, 10, 28,  0,  0,  0],\n",
       "        [20, 27,  8, 22, 20,  7,  9,  4,  0,  0],\n",
       "        [15, 19,  7, 28, 26, 27,  0,  0,  0,  0],\n",
       "        [19,  7,  9,  3, 12, 21, 20, 12,  0,  0],\n",
       "        [26, 16, 20, 14, 14, 27,  4,  4,  0,  0],\n",
       "        [15, 17, 19,  9, 15, 19, 26,  6, 18,  0],\n",
       "        [16,  5, 19, 27, 11, 15,  0,  0,  0,  0],\n",
       "        [17, 11, 24, 20,  7, 17,  0,  0,  0,  0],\n",
       "        [16, 19,  9, 28,  4,  3,  0,  0,  0,  0],\n",
       "        [23, 18,  4,  8, 17,  4, 20, 14,  0,  0],\n",
       "        [24, 21, 19,  5,  4, 10,  8, 18, 26,  0],\n",
       "        [ 6, 22,  5, 11,  7, 23,  7, 17,  0,  0],\n",
       "        [19, 15, 25, 13,  4, 13,  0,  0,  0,  0],\n",
       "        [26,  7, 21,  5, 22, 19,  0,  0,  0,  0],\n",
       "        [ 5,  9,  4, 26, 13, 20,  9, 15,  0,  0],\n",
       "        [10, 23, 28,  6, 22, 11,  6, 12, 18, 15],\n",
       "        [ 3, 17, 23,  6,  8, 23,  4,  0,  0,  0],\n",
       "        [ 5, 24, 20, 11, 18, 23, 12,  3, 26,  0],\n",
       "        [20, 11, 22,  5,  5, 18, 24,  0,  0,  0],\n",
       "        [18, 16,  8,  6, 16,  8, 21, 27,  0,  0],\n",
       "        [ 3,  8, 23,  7, 23, 16,  8,  3,  7,  0],\n",
       "        [18, 22,  5, 23,  6, 24,  0,  0,  0,  0],\n",
       "        [ 4, 18,  5,  8, 23, 11, 12, 10, 28, 16],\n",
       "        [ 3, 26, 16, 23, 11,  8, 20,  9, 15, 12],\n",
       "        [ 6, 26,  8,  5, 16, 13, 18,  9, 20, 28],\n",
       "        [28, 17,  4, 20, 22, 10,  8,  0,  0,  0],\n",
       "        [ 9, 26, 24, 14, 10, 19,  0,  0,  0,  0],\n",
       "        [20, 12, 15, 15, 25, 28, 16, 15, 28,  0],\n",
       "        [28, 13,  9, 23,  6, 26, 16, 23, 25, 11],\n",
       "        [19, 28, 18, 27, 21, 17, 11,  5,  0,  0],\n",
       "        [ 6, 27, 15, 16, 16, 14,  0,  0,  0,  0]]),\n",
       " array([[ 1,  3, 27, 18,  9, 14, 23, 27, 28,  0,  0],\n",
       "        [ 1, 28, 10,  5, 17,  7, 18, 13,  0,  0,  0],\n",
       "        [ 1,  4,  9,  7, 20, 22,  8, 27, 20,  0,  0],\n",
       "        [ 1, 27, 26, 28,  7, 19, 15,  0,  0,  0,  0],\n",
       "        [ 1, 12, 20, 21, 12,  3,  9,  7, 19,  0,  0],\n",
       "        [ 1,  4,  4, 27, 14, 14, 20, 16, 26,  0,  0],\n",
       "        [ 1, 18,  6, 26, 19, 15,  9, 19, 17, 15,  0],\n",
       "        [ 1, 15, 11, 27, 19,  5, 16,  0,  0,  0,  0],\n",
       "        [ 1, 17,  7, 20, 24, 11, 17,  0,  0,  0,  0],\n",
       "        [ 1,  3,  4, 28,  9, 19, 16,  0,  0,  0,  0],\n",
       "        [ 1, 14, 20,  4, 17,  8,  4, 18, 23,  0,  0],\n",
       "        [ 1, 26, 18,  8, 10,  4,  5, 19, 21, 24,  0],\n",
       "        [ 1, 17,  7, 23,  7, 11,  5, 22,  6,  0,  0],\n",
       "        [ 1, 13,  4, 13, 25, 15, 19,  0,  0,  0,  0],\n",
       "        [ 1, 19, 22,  5, 21,  7, 26,  0,  0,  0,  0],\n",
       "        [ 1, 15,  9, 20, 13, 26,  4,  9,  5,  0,  0],\n",
       "        [ 1, 15, 18, 12,  6, 11, 22,  6, 28, 23, 10],\n",
       "        [ 1,  4, 23,  8,  6, 23, 17,  3,  0,  0,  0],\n",
       "        [ 1, 26,  3, 12, 23, 18, 11, 20, 24,  5,  0],\n",
       "        [ 1, 24, 18,  5,  5, 22, 11, 20,  0,  0,  0],\n",
       "        [ 1, 27, 21,  8, 16,  6,  8, 16, 18,  0,  0],\n",
       "        [ 1,  7,  3,  8, 16, 23,  7, 23,  8,  3,  0],\n",
       "        [ 1, 24,  6, 23,  5, 22, 18,  0,  0,  0,  0],\n",
       "        [ 1, 16, 28, 10, 12, 11, 23,  8,  5, 18,  4],\n",
       "        [ 1, 12, 15,  9, 20,  8, 11, 23, 16, 26,  3],\n",
       "        [ 1, 28, 20,  9, 18, 13, 16,  5,  8, 26,  6],\n",
       "        [ 1,  8, 10, 22, 20,  4, 17, 28,  0,  0,  0],\n",
       "        [ 1, 19, 10, 14, 24, 26,  9,  0,  0,  0,  0],\n",
       "        [ 1, 28, 15, 16, 28, 25, 15, 15, 12, 20,  0],\n",
       "        [ 1, 11, 25, 23, 16, 26,  6, 23,  9, 13, 28],\n",
       "        [ 1,  5, 11, 17, 21, 27, 18, 28, 19,  0,  0],\n",
       "        [ 1, 14, 16, 16, 15, 27,  6,  0,  0,  0,  0]]),\n",
       " array([[ 3, 27, 18,  9, 14, 23, 27, 28,  0,  0,  0],\n",
       "        [28, 10,  5, 17,  7, 18, 13,  0,  0,  0,  0],\n",
       "        [ 4,  9,  7, 20, 22,  8, 27, 20,  0,  0,  0],\n",
       "        [27, 26, 28,  7, 19, 15,  0,  0,  0,  0,  0],\n",
       "        [12, 20, 21, 12,  3,  9,  7, 19,  0,  0,  0],\n",
       "        [ 4,  4, 27, 14, 14, 20, 16, 26,  0,  0,  0],\n",
       "        [18,  6, 26, 19, 15,  9, 19, 17, 15,  0,  0],\n",
       "        [15, 11, 27, 19,  5, 16,  0,  0,  0,  0,  0],\n",
       "        [17,  7, 20, 24, 11, 17,  0,  0,  0,  0,  0],\n",
       "        [ 3,  4, 28,  9, 19, 16,  0,  0,  0,  0,  0],\n",
       "        [14, 20,  4, 17,  8,  4, 18, 23,  0,  0,  0],\n",
       "        [26, 18,  8, 10,  4,  5, 19, 21, 24,  0,  0],\n",
       "        [17,  7, 23,  7, 11,  5, 22,  6,  0,  0,  0],\n",
       "        [13,  4, 13, 25, 15, 19,  0,  0,  0,  0,  0],\n",
       "        [19, 22,  5, 21,  7, 26,  0,  0,  0,  0,  0],\n",
       "        [15,  9, 20, 13, 26,  4,  9,  5,  0,  0,  0],\n",
       "        [15, 18, 12,  6, 11, 22,  6, 28, 23, 10,  0],\n",
       "        [ 4, 23,  8,  6, 23, 17,  3,  0,  0,  0,  0],\n",
       "        [26,  3, 12, 23, 18, 11, 20, 24,  5,  0,  0],\n",
       "        [24, 18,  5,  5, 22, 11, 20,  0,  0,  0,  0],\n",
       "        [27, 21,  8, 16,  6,  8, 16, 18,  0,  0,  0],\n",
       "        [ 7,  3,  8, 16, 23,  7, 23,  8,  3,  0,  0],\n",
       "        [24,  6, 23,  5, 22, 18,  0,  0,  0,  0,  0],\n",
       "        [16, 28, 10, 12, 11, 23,  8,  5, 18,  4,  0],\n",
       "        [12, 15,  9, 20,  8, 11, 23, 16, 26,  3,  0],\n",
       "        [28, 20,  9, 18, 13, 16,  5,  8, 26,  6,  0],\n",
       "        [ 8, 10, 22, 20,  4, 17, 28,  0,  0,  0,  0],\n",
       "        [19, 10, 14, 24, 26,  9,  0,  0,  0,  0,  0],\n",
       "        [28, 15, 16, 28, 25, 15, 15, 12, 20,  0,  0],\n",
       "        [11, 25, 23, 16, 26,  6, 23,  9, 13, 28,  0],\n",
       "        [ 5, 11, 17, 21, 27, 18, 28, 19,  0,  0,  0],\n",
       "        [14, 16, 16, 15, 27,  6,  0,  0,  0,  0,  0]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,train_y1,train_y2 = create_dataset(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367f3bb",
   "metadata": {},
   "source": [
    "## 2. Basic model\n",
    "\n",
    "- No mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85d664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.models.Model):\n",
    "    def __init__(self,vocab_size,embed_size = 50,units = 128,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_layer = keras.layers.Embedding(input_dim = vocab_size,output_dim = embed_size)\n",
    "        self.lstm_layer = keras.layers.LSTM(units,return_sequences = True,return_state = True)\n",
    "        \n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        embed = self.embedding_layer(inputs)\n",
    "        encoder_output, state_h,state_c = self.lstm_layer(embed)\n",
    "        encoder_state = [state_h,state_c]\n",
    "        \n",
    "        return encoder_output,encoder_state\n",
    "    \n",
    "    \n",
    "class Decoder(keras.models.Model):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size=50,units = 128,**kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.embedding_layer = keras.layers.Embedding(input_dim=  vocab_size,output_dim=embed_size)\n",
    "        self.lstm_layer = keras.layers.LSTM(units,return_sequences = True,return_state = True)\n",
    "        \n",
    "    def call(self,inputs,state):\n",
    "        \n",
    "        embed = self.embedding_layer(inputs)\n",
    "        decoder_output,state_h,state_c = self.lstm_layer(embed,initial_state = state)\n",
    "        \n",
    "        decoder_state = [state_h,state_c]\n",
    "        \n",
    "        \n",
    "        return decoder_output,decoder_state\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f62ca3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.layers.Input(shape = [None],name = 'encoder_inputs')\n",
    "decoder_inputs = keras.layers.Input(shape = [None],name = 'decoder_inputs')\n",
    "\n",
    "encoder_output,encoder_state = Encoder(vocab_size=len(words_to_ids))(encoder_inputs)\n",
    "decoder_output,decoder_state = Decoder(vocab_size=len(words_to_ids))(decoder_inputs,encoder_state)\n",
    "\n",
    "output = keras.layers.Dense(len(words_to_ids),activation = 'softmax',name = 'dense')(decoder_output)\n",
    "\n",
    "model = keras.models.Model([encoder_inputs,decoder_inputs],[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.fit([train_x,train_y1],train_y2,epochs = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
