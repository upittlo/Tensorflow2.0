{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#莎士比亞的科利奧蘭納斯劇本，是莎士比亞晚期的作品\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料，並且格式轉換為utf-8\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# 確認\b字數量\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# 觀察前100個字\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 個不重複的文字\n"
     ]
    }
   ],
   "source": [
    "# 觀察不重複字元\n",
    "vocab = sorted(set(text))\n",
    "print('{} 個不重複的文字'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " '\\n':   0,\n",
      " ' ' :   1,\n",
      " '!' :   2,\n",
      " '$' :   3,\n",
      " '&' :   4,\n",
      " \"'\" :   5,\n",
      " ',' :   6,\n",
      " '-' :   7,\n",
      " '.' :   8,\n",
      " '3' :   9,\n",
      " ':' :  10,\n",
      " ';' :  11,\n",
      " '?' :  12,\n",
      " 'A' :  13,\n",
      " 'B' :  14,\n",
      " 'C' :  15,\n",
      " 'D' :  16,\n",
      " 'E' :  17,\n",
      " 'F' :  18,\n",
      " 'G' :  19,\n",
      "   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx,range(20)):\n",
    "    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n",
    "print('   ...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字： First Citi 代號： [18 47 56 57 58  1 15 47 58 47]\n"
     ]
    }
   ],
   "source": [
    "# 展示前面10個文字轉換後的代號\n",
    "print('文字：',text[:10],'代號：',text_as_int[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用 from_tensor_slices 函數，自陣列建立 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "#設定最長輸入的句子\n",
    "\n",
    "seq_length = 100\n",
    "example_per_epoch = len(text) // (seq_length+1)\n",
    "\n",
    "#建立訓練資料與預測目標\n",
    "# from_tensor_slice: can input numpy array as dataset\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1,drop_remainder = True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chuck):\n",
    "    input_text = chuck[:-1]\n",
    "    target_text = chuck[1:]\n",
    "    return input_text,target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "#前一個輸入的文字，預測下一個輸入的文字\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('F')\n",
      "  expected output: 47 ('i')\n",
      "Step    1\n",
      "  input: 47 ('i')\n",
      "  expected output: 56 ('r')\n",
      "Step    2\n",
      "  input: 56 ('r')\n",
      "  expected output: 57 ('s')\n",
      "Step    3\n",
      "  input: 57 ('s')\n",
      "  expected output: 58 ('t')\n",
      "Step    4\n",
      "  input: 58 ('t')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n",
    "#以First為例，用F去預測i，用i去預測r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立以65字元vocab_size\n",
    "vocab_size = len(vocab)\n",
    "# 設定詞嵌入的維度\n",
    "embedding_dim = 256\n",
    "# 設定RNN所使用的單元數\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape = [batch_size,None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                           return_sequences = True,\n",
    "                           stateful = True,\n",
    "                           recurrent_initializer = 'glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = len(vocab),\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    rnn_units = rnn_units,\n",
    "                    batch_size = BATCH_SIZE\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (批次大小、序列長度、字詞的數量)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (批次大小、序列長度、字詞的數量)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  7, 31, 33, 23, 16, 22, 15, 57, 11, 37, 44, 50, 40, 58,  8, 61,\n",
       "       26,  7, 14, 60, 52,  1, 21, 59,  2, 45, 17, 64, 56, 52, 46, 35, 55,\n",
       "       50, 36, 15, 24,  3, 50, 56, 64, 28, 16, 26, 53,  7, 24, 46,  6, 19,\n",
       "       44, 35, 52, 61, 24, 36, 30,  4, 36, 36, 16, 48,  2, 22, 31, 45,  7,\n",
       "       31, 31, 40, 41, 20, 41, 29, 29, 52, 30, 14, 14, 36, 49, 30, 46, 15,\n",
       "       32, 44, 11, 45, 28, 38, 24, 42, 22, 56, 51,  9, 36, 56, 25],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices = tf.random.categorical(example_batch_predictions[0],num_samples = 1)\n",
    "sample_indices = tf.squeeze(sample_indices,axis = -1).numpy()\n",
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入: \n",
      " ' many hours bring about the day;\\nHow many days will finish up the year;\\nHow many years a mortal man '\n",
      "\n",
      "下一個預測的文字: \n",
      " 'D-SUKDJCs;Yflbt.wN-Bvn Iu!gEzrnhWqlXCL$lrzPDNo-Lh,GfWnwLXR&XXDj!JSg-SSbcHcQQnRBBXkRhCTf;gPZLdJrm3XrM'\n"
     ]
    }
   ],
   "source": [
    "### 訓練前  測試預測結果(未訓練狀態)\n",
    "\n",
    "print(\"輸入: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"下一個預測的文字: \\n\", repr(\"\".join(idx2char[sample_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 6s 37ms/step - loss: 2.6708\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 6s 35ms/step - loss: 1.9683\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 6s 35ms/step - loss: 1.7012\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 6s 36ms/step - loss: 1.5503\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 6s 36ms/step - loss: 1.4606\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 6s 36ms/step - loss: 1.4005\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 6s 36ms/step - loss: 1.3532\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 6s 35ms/step - loss: 1.3146\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 6s 35ms/step - loss: 1.2799\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 6s 35ms/step - loss: 1.2474\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True)\n",
    "\n",
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits = True)\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = loss)\n",
    "\n",
    "history = model.fit(dataset,epochs = 10,callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(vocab_size,embedding_dim,rnn_units,batch_size = 1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_string):\n",
    "    \n",
    "    num_generate = 1000\n",
    "    \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = 1.0\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "        \n",
    "        predictions = predictions/temperature\n",
    "        predicted_id = tf.random.categorical(predictions,num_samples = 1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id],0)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return start_string+''.join(text_generated)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "To this hag such grace when thou does promiderate\n",
      "A pilch that paris on a rittle give me: when I say,\n",
      "More since fettiting agest but at overdorn?\n",
      "O my cousin Hereford;' Sirta to Mortagues; or do such inflements\n",
      "To strangle; for a plague thee,\n",
      "Since you ingent as kingly great.\n",
      "\n",
      "Come,\n",
      "Be worse cannations to the world rumesy\n",
      "in him and for death. All thinks,\n",
      "That we need will have brought you of a husband;\n",
      "And seek to look into you say\n",
      "What 'eardenius, Petruchio, and thou treado peace,\n",
      "And ann go set them, duty you draw importing\n",
      "Largest not, Was off?\n",
      "\n",
      "ROMEO:\n",
      "Thou dost saw ay thou wilt swore! wherein they didst not\n",
      "throgal thousand wives to see\n",
      "O heavy unmurnels: so be it straight to stand in your\n",
      "A fear of golden stretch-doublord, it full and angry great Paris,\n",
      "That sour live to suspect him to be most royalty,\n",
      "If not, my lord.\n",
      "\n",
      "KING HENRY VI:\n",
      "Saveg York was little to be aboved!\n",
      "Saying, so take them safely, as thow is come.\n",
      "\n",
      "ISABELLA:\n",
      "He earnd and many home,\n",
      "Her note to end, trust to\n",
      "af\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"First Citizen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
