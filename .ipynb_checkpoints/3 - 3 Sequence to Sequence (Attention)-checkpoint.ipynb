{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#西班牙文翻英文\n",
    "#資料來源http://www.manythings.org/anki/\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "- 標準化編碼: unicodedata.normalize('NFD',s)\n",
    "\n",
    "    reference: https://blog.csdn.net/weixin_43866211/article/details/98384017\n",
    "</p><p/>\n",
    "- 將每個句子增加開始與結束標記\n",
    "- 刪除特殊符號\n",
    "- 建立單詞索引\n",
    "- 將句子進行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>' #開始與結束\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "## Test result\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 清除重音\n",
    "- 清理句子\n",
    "- 整理回傳的句子\n",
    "\n",
    "#### Note: fit_on_texts, when applied on a string text, its attributes produce different types of results\n",
    "\n",
    "- tokenizer 可用 index_word將數字轉回文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path,num_examples):\n",
    "    lines = io.open(path,encoding = 'UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    \n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file,None)\n",
    "print(en[-1])\n",
    "print(sp[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding = 'post')\n",
    "    \n",
    "    return tensor,lang_tokenizer\n",
    "\n",
    "def load_dataset(path,num_examples = None):\n",
    "    \n",
    "    ## input,output pairs\n",
    "    targ_lang,inp_lang = create_dataset(path,num_examples)\n",
    "    input_tensor,inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor,targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer,targ_lang_tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor,target_tensor,inp_lang,targ_lang = load_dataset(path_to_file,num_examples)\n",
    "max_length_targ,max_length_inp = max_length(target_tensor), max_length(input_tensor)   #計算最大長度的張量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆分80%訓練、20%測試\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 確認長度\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index to word function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入; 文字索引\n",
      "1 ----> <start>\n",
      "2020 ----> eh\n",
      "27 ----> !\n",
      "32 ----> ,\n",
      "8 ----> no\n",
      "52 ----> eres\n",
      "4 ----> tom\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "目標; 文字索引\n",
      "1 ----> <start>\n",
      "584 ----> hey\n",
      "49 ----> ,\n",
      "6 ----> you\n",
      "23 ----> re\n",
      "34 ----> not\n",
      "5 ----> tom\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang,tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "            \n",
    "print (\"輸入; 文字索引\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"目標; 文字索引\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_tensor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#透過tf.data，將input_tensor_train與target_tensor_train做資料整理，以提升運算效率\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "#依據input_tensor_train筆數建立BUFFER，進行shuffle\n",
    "BATCH_SIZE = 64\n",
    "#取整數作為每一次epoch的steps\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE \n",
    "embedding_dim = 256\n",
    "#GRU的單元數\n",
    "units = 1024\n",
    "\n",
    "#預測內容是西班牙文，預測目標是英文\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE,drop_remainder = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 16), dtype=int32, numpy=\n",
       " array([[   1,   25, 5737, ...,    0,    0,    0],\n",
       "        [   1,    8,  839, ...,    0,    0,    0],\n",
       "        [   1,   28, 1092, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,    6,   46, ...,    0,    0,    0],\n",
       "        [   1,    6,   22, ...,    0,    0,    0],\n",
       "        [   1,  277, 1277, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
       " array([[   1,   27,  760, 1402,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   30,   12,  450,  190,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   20,   38,   73,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   32,   24,  247,   54,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,   35,  618,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   27,  968,   41,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    6,   24, 1797,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,  177,   52,    4,   22,   10,    3,    2,    0,    0,    0],\n",
       "        [   1,   14,  173,   17,    9, 2527,    3,    2,    0,    0,    0],\n",
       "        [   1,   19,  831,    8,  198,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    6,   23,  326,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   56,  497,   17,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    8,   19,  424,    7,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    5,  270,  115,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    6,   24,  155,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   14,   11,    9,  443,  159,    3,    2,    0,    0,    0],\n",
       "        [   1,   10,   11,   34, 1605,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   32,   16,   63,    8,   73,    3,    2,    0,    0,    0],\n",
       "        [   1,   60, 1309,  119,   20,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,  257,    6,   85,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,   42,   20,  355,  265,    3,    2,    0,    0,    0],\n",
       "        [   1,   75,    6,   73,   17,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,   22,   34,   53,   39,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    6,   24,   13,   84,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,  222, 2325,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   10,   11, 1221,   17,  275,    3,    2,    0,    0,    0],\n",
       "        [   1, 2133,   35, 1971,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   27, 1056,  109,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    8,   14,   91,  210,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,   21,  226,   26,  148,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    5,   11,  348,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1, 1015,   37,    2,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   62, 1089,   59,  341,    3,    2,    0,    0,    0],\n",
       "        [   1,    4,   25, 1305,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   39,   49,  207,   19,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   27,    8,   70,    9,  466,    3,    2,    0,    0,    0],\n",
       "        [   1,  187,   11,  991,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   27,   51,  306, 1553,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   10,   11,  664,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,  321,  314,   15,   41,    3,    2,    0,    0,    0],\n",
       "        [   1,   27,  121,   15,  295,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    5,   42,   10,   44,   61,  432,    3,    2,    0,    0],\n",
       "        [   1,    5, 1225,   61,  995,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   32,   92,    6, 1171,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,   98,   17,   79, 1857,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    5,  386,   81,    9,  153,    3,    2,    0,    0,    0],\n",
       "        [   1,    6,  292,   40,  107,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,   29,  105,   13,  385,    3,    2,    0,    0,    0],\n",
       "        [   1,    8,   10,  263,    7,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   27,  366,   15,  246,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   22,    6,   47,    9, 1802,    7,    2,    0,    0,    0],\n",
       "        [   1,   19,  467,    8,  248,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   16,   87,   12,  171,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   57,    8,    9, 2498,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   66,   84,   75,  192,    6,    3,    2,    0,    0,    0],\n",
       "        [   1,  314,  409,   49,   56,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    4,  209,   42,   21,  729,    3,    2,    0,    0,    0],\n",
       "        [   1,    4,   38,   73,    5,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,   14,  598,   42,   10,    3,    2,    0,    0,    0,    0],\n",
       "        [   1,    6,  117,   10,    3,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    8,    5,   89,    7,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   60, 1524,    6,    7,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,   82,   24,   16,  378,    7,    2,    0,    0,    0,    0],\n",
       "        [   1,   16, 2157,   31,   73,    3,    2,    0,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成迭代器觀察內容與目標\n",
    "example_input_batch,example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape,example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
       "array([[   1,   28,   23,  186,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   28,  135,  225,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   13, 2904,    8,  297,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,  703,  176,   12, 1115,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,  379,   11,  348,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,    4,  656,   12, 1110,  358,    3,    2,    0,    0,    0],\n",
       "       [   1,   10,   11,  219,  248,  219,   20,    3,    2,    0,    0],\n",
       "       [   1,   10,  106,  478,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   14,   25,  174,  163,  317,    3,    2,    0,    0,    0],\n",
       "       [   1,   22,    6,   43,   68,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,   75, 1905,    6,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   19,    8,  155,  501,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,  251,   15,  174,  126,    3,    2,    0,    0,    0],\n",
       "       [   1,    4,   70,  384,   58,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   26,    4,  184,    7,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   27,    8,   21, 1296,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   24,    6,  645,    7,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,    4,   18,  762, 1465,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,   43,   71,   15,  264,    3,    2,    0,    0,    0],\n",
       "       [   1,   64, 1114,    3,    2,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   14,    8,    9,  640,  159,    3,    2,    0,    0,    0],\n",
       "       [   1,   32,   24,    6,   69,   55,    7,    2,    0,    0,    0],\n",
       "       [   1,   62,    4,  933,  462,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,   86, 2177,   17,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   10,   26,  130,  214,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,   38,   72,    6,  916,    3,    2,    0,    0,    0],\n",
       "       [   1, 2206, 3682,    3,    2,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   10,   26,   21,  259,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   22,    6,   47,   41,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,   22,    6,   47,    9,  356,    7,    2,    0,    0,    0],\n",
       "       [   1,   30,   12,   40,  193,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    6,   23,  559,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   42,    6,  481,   41,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,   39,   49,  125,   10,   44,    3,    2,    0,    0,    0],\n",
       "       [   1,    5,   25,  368,  101,   58,    3,    2,    0,    0,    0],\n",
       "       [   1,  441,   10,   25,   40, 1002,    3,    2,    0,    0,    0],\n",
       "       [   1,   68,  189,    8,   33,  592,    3,    2,    0,    0,    0],\n",
       "       [   1,   14,  179,   68,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   16,  250,   68,  309,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,  806,  195,    3,    2,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   16,   29,  140,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   14,   51,    9,  427,   44,    3,    2,    0,    0,    0],\n",
       "       [   1,   14, 2258,   61,  565,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   13,  515,    8,  197,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   10,    8,   34,    9,  177,    3,    2,    0,    0,    0],\n",
       "       [   1,   32,   24,  247,   54,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,   16,   38,  422,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,  462,   24,  308,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,    5,    8,    9, 3800,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   46,   11, 1025,    5,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   16,   65,  362,   68,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    6,   29,  140,  300,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   27,  276,   67,  437,    3,    2,    0,    0,    0,    0],\n",
       "       [   1, 1607,   31,  710,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   20,   11, 4460,    3,    2,    0,    0,    0,    0,    0],\n",
       "       [   1,   24,    6,  612,   55,   17,    7,    2,    0,    0,    0],\n",
       "       [   1,   27,   51,  701,  325,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,   71,   11,   13,  422,    7,    2,    0,    0,    0,    0],\n",
       "       [   1,   10,   90,   12,    9,  370,    3,    2,    0,    0,    0],\n",
       "       [   1,   30,   12,   36,   85,  224,   37,    2,    0,    0,    0],\n",
       "       [   1,    5,  121,  408,  215,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,  114,   27,    8,  232,    3,    2,    0,    0,    0],\n",
       "       [   1,   13, 4856,  338,  594,    3,    2,    0,    0,    0,    0],\n",
       "       [   1,    4,   38,   40,   48,  630,    3,    2,    0,    0,    0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_sz):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_sz = batch_sz  #BATCH_SIZE\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim) #每一個單詞轉為Embedding\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                      return_sequences = True,\n",
    "                                      return_state = True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')  #均勻初始化\n",
    "        \n",
    "    def call(self,x,hidden): #做一層embedding+GRU\n",
    "        x = self.embedding(x)\n",
    "        output,state = self.gru(x,initial_state = hidden) #每一次初始化為Hidden的變數\n",
    "        \n",
    "        return output,state\n",
    "    \n",
    "    def initialize_hidden_state(self): # 建立空的初始化\n",
    "        return tf.zeros((self.batch_sz,self.enc_units))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size,embedding_dim,units,BATCH_SIZE) #依據vocab_inp_size、embedding_dim、單元數、BATCH_SIZE建立Encoder\n",
    "\n",
    "# 輸入的樣本\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state() #依據Batch_sz與enc_units初始化\n",
    "sample_output,sample_hidden = encoder(example_input_batch,sample_hidden)  #觀察一下預測內容與具備GRU單元數的隱藏層樣態\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape)) #sample_output（批次大小、訓練資料長度、單元數）\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape)) #sample_hidden（批次大小、單元數）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__() #繼承TF的BahdanauAttention\n",
    "        self.W1 = tf.keras.layers.Dense(units) #依據GRU的單元數進行Dense\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self,query,values):\n",
    "         # 執行加法計算分數，先將讓query多一個維度，相加之後做一個tanh，獲得分數，score = FC(tanh(FC(EO) + FC(H)))\n",
    "            \n",
    "        hidden_with_time_axis = tf.expand_dims(query,1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values)+self.W2(hidden_with_time_axis)))\n",
    "         # attention weights = softmax(score, axis = 1) \n",
    "        attention_weights = tf.nn.softmax(score,axis = 1)\n",
    "        # context_vector = sum(attention weights * EO, axis = 1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector,axis = 1)\n",
    "        \n",
    "        return context_vector,attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10) #Attention的強度\n",
    "attention_result,attention_weights = attention_layer(sample_hidden,sample_output) #將初始化空的sample_hidden與要進行預測內容\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,dec_units,batch_sz): #詞彙、embedding維度、單元數、批次大小\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding =tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                      return_sequences = True,\n",
    "                                      return_state = True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self,x,hidden,enc_output):\n",
    "        # 透過BahdanauAttention建立context_vector、attention_weights\n",
    "        \n",
    "        context_vector,attention_weights = self.attention(hidden,enc_output)\n",
    "        \n",
    "        # 做一次embedding\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = tf.concat([tf.expand_dims(context_vector,1),x],axis = -1)\n",
    "        \n",
    "        # 將x給GRU計算後回報結果與狀態\n",
    "        output,state = self.gru(x)\n",
    "        \n",
    "        # 資料維度整理\n",
    "        output = tf.reshape(output,(-1,output.shape[2]))\n",
    "        \n",
    "        # 做線性轉換後輸出\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x,state,attention_weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE) #依據詞彙、embedding維度、單元數、批次大小進行Decoder\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)), #隨機產生批次大小的資料作為起始值、sample_hidden初始值、預測內容\n",
    "                                      sample_hidden, sample_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits = True,reduction = 'none')\n",
    "\n",
    "def loss_function(real,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0)) #將數字轉換為邏輯值\n",
    "    loss_ = loss_object(real,pred) #透過loss_object做Crossentropy計算\n",
    "    #透過tf.cast做函數轉換，如：1轉True\n",
    "    mask = tf.cast(mask,dtype = loss_.dtype)\n",
    "    \n",
    "    loss_ *=mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#記錄每一次計算的Checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #加上tf.function修飾器\n",
    "\n",
    "def train_step(inp,targ,enc_hidden):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        #通過編碼器傳遞輸入，編碼器產生「編碼器輸出」和「編碼器隱藏狀態」。\n",
    "        enc_output,enc_hidden = encoder(inp,enc_hidden)\n",
    "        \n",
    "        #將「編碼器隱藏狀態」傳給「解碼器的隱藏狀態」\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE,1)\n",
    "        \n",
    "        \n",
    "        # 將預測結果作為下一個輸入\n",
    "        \n",
    "        for t in range(1,targ.shape[1]):\n",
    "            # 解碼器返回「預測值」和「解碼器隱藏狀態」。\n",
    "            \n",
    "            predictions,dec_hidden,_ = decoder(dec_input,dec_hidden,enc_output)\n",
    "            \n",
    "             # 將答案與predictions做Loss計算\n",
    "                \n",
    "            loss += loss_function(targ[:,t],predictions)\n",
    "            \n",
    "            # 將預測目標，作為下一個解碼器dec_input的輸入\n",
    "            \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        \n",
    "        #紀錄每一次的自動微分結果\n",
    "    gradients = tape.gradient(loss,variables)\n",
    "        \n",
    "        #進行優化器計算\n",
    "        \n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "        \n",
    "    return batch_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6268\n",
      "Epoch 1 Batch 100 Loss 2.3243\n",
      "Epoch 1 Batch 200 Loss 2.2149\n",
      "Epoch 1 Batch 300 Loss 2.1368\n",
      "Epoch 1 Loss 2.3686\n",
      "Time taken for 1 epoch 27.534215927124023 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.8826\n",
      "Epoch 2 Batch 100 Loss 1.9751\n",
      "Epoch 2 Batch 200 Loss 1.8416\n",
      "Epoch 2 Batch 300 Loss 1.6975\n",
      "Epoch 2 Loss 1.8477\n",
      "Time taken for 1 epoch 19.8075430393219 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.6714\n",
      "Epoch 3 Batch 100 Loss 1.5202\n",
      "Epoch 3 Batch 200 Loss 1.5141\n",
      "Epoch 3 Batch 300 Loss 1.5121\n",
      "Epoch 3 Loss 1.5173\n",
      "Time taken for 1 epoch 19.821372509002686 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3062\n",
      "Epoch 4 Batch 100 Loss 1.2983\n",
      "Epoch 4 Batch 200 Loss 1.2043\n",
      "Epoch 4 Batch 300 Loss 1.1686\n",
      "Epoch 4 Loss 1.2430\n",
      "Time taken for 1 epoch 19.89768362045288 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.1125\n",
      "Epoch 5 Batch 100 Loss 1.0298\n",
      "Epoch 5 Batch 200 Loss 0.9643\n",
      "Epoch 5 Batch 300 Loss 0.9032\n",
      "Epoch 5 Loss 1.0057\n",
      "Time taken for 1 epoch 19.86258816719055 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7930\n",
      "Epoch 6 Batch 100 Loss 0.8201\n",
      "Epoch 6 Batch 200 Loss 0.8934\n",
      "Epoch 6 Batch 300 Loss 0.7890\n",
      "Epoch 6 Loss 0.7896\n",
      "Time taken for 1 epoch 19.877053260803223 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.5409\n",
      "Epoch 7 Batch 100 Loss 0.6230\n",
      "Epoch 7 Batch 200 Loss 0.6251\n",
      "Epoch 7 Batch 300 Loss 0.6845\n",
      "Epoch 7 Loss 0.6203\n",
      "Time taken for 1 epoch 19.824842929840088 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.4218\n",
      "Epoch 8 Batch 100 Loss 0.6056\n",
      "Epoch 8 Batch 200 Loss 0.5268\n",
      "Epoch 8 Batch 300 Loss 0.4837\n",
      "Epoch 8 Loss 0.4749\n",
      "Time taken for 1 epoch 19.85976815223694 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3104\n",
      "Epoch 9 Batch 100 Loss 0.3256\n",
      "Epoch 9 Batch 200 Loss 0.3629\n",
      "Epoch 9 Batch 300 Loss 0.3856\n",
      "Epoch 9 Loss 0.3728\n",
      "Time taken for 1 epoch 19.862656116485596 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2597\n",
      "Epoch 10 Batch 100 Loss 0.2097\n",
      "Epoch 10 Batch 200 Loss 0.3596\n",
      "Epoch 10 Batch 300 Loss 0.2928\n",
      "Epoch 10 Loss 0.2924\n",
      "Time taken for 1 epoch 22.822256565093994 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#開始訓練模型\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    #將預測內容、預測目標放入\n",
    "    \n",
    "    for (batch,(inp,targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp,targ,enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "\n",
    "    \n",
    "  # 每兩個epochs就儲存一次checkpoint\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                  total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \n",
    "    attention_plot = np.zeros((max_length_targ,max_length_inp))  #建立最大的輸入與預測目標\n",
    "    \n",
    "    #將資料做前處理，如去除符號、轉tensor..等\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen = max_length_inp,\n",
    "                                                           padding = 'post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1,units))]\n",
    "    \n",
    "    #透過encoder產生出輸出與狀態\n",
    "    \n",
    "    enc_out,enc_hidden = encoder(inputs,hidden)\n",
    "    \n",
    "    #編碼層的狀態一樣給解碼層(dec_hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']],0)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        # 透過decoder解碼，獲得預測結果、解碼狀態、注意力權重\n",
    "        predictions,dec_hidden,attention_weights = decoder(dec_input,dec_hidden,enc_out)\n",
    "        \n",
    "        # 儲存注意力權重\n",
    "        attention_weights = tf.reshape(attention_weights,(-1,))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # 將預測ID回饋到模型\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        \n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence,attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id],0)\n",
    "        \n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製注意力視覺化\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將模型用來做結果預測\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it expensive very cold here here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure to out out . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
