{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "specific-permit",
   "metadata": {},
   "source": [
    "### TF2.0 Hello world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latest-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-analysis",
   "metadata": {},
   "source": [
    "### Create sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "novel-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3)\n",
    "    \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 7ms/sample - loss: 1.2428 - accuracy: 0.3238\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.1120 - accuracy: 0.3714\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.0062 - accuracy: 0.4095\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.0119 - accuracy: 0.4857\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.9293 - accuracy: 0.6571\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8398 - accuracy: 0.6476\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.9446 - accuracy: 0.6381\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8450 - accuracy: 0.7048\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7671 - accuracy: 0.7714\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8173 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.6948 - accuracy: 0.7524\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7155 - accuracy: 0.7238\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7036 - accuracy: 0.7048\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.6996 - accuracy: 0.6762\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.6737 - accuracy: 0.6952\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.6351 - accuracy: 0.7524\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5639 - accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5945 - accuracy: 0.7810\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 133us/sample - loss: 0.6017 - accuracy: 0.7905\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.6067 - accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.5856 - accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.5943 - accuracy: 0.7333\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5719 - accuracy: 0.7238\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5068 - accuracy: 0.8095\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.5357 - accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5367 - accuracy: 0.7810\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4896 - accuracy: 0.7905\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4650 - accuracy: 0.7905\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.5008 - accuracy: 0.8095\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.4461 - accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.4501 - accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4180 - accuracy: 0.8857\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.4277 - accuracy: 0.8286\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4804 - accuracy: 0.7619\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4161 - accuracy: 0.8857\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4034 - accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4114 - accuracy: 0.8381\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4064 - accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.4055 - accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3971 - accuracy: 0.8286\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3849 - accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.4032 - accuracy: 0.8095\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.3978 - accuracy: 0.8286\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.4026 - accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3737 - accuracy: 0.8286\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3392 - accuracy: 0.8762\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3609 - accuracy: 0.8762\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3207 - accuracy: 0.9333\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.3083 - accuracy: 0.9238\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3484 - accuracy: 0.8952\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2969 - accuracy: 0.9048\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 0.3081 - accuracy: 0.9238\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.3177 - accuracy: 0.9048\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3386 - accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2970 - accuracy: 0.9524\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3198 - accuracy: 0.8952\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3006 - accuracy: 0.9238\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.3568 - accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2948 - accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3132 - accuracy: 0.9048\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2845 - accuracy: 0.9429\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3225 - accuracy: 0.8857\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.3143 - accuracy: 0.8952\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2853 - accuracy: 0.9143\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2594 - accuracy: 0.9429\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2966 - accuracy: 0.8952\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2901 - accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2962 - accuracy: 0.8762\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2904 - accuracy: 0.9238\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2569 - accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2570 - accuracy: 0.9238\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2246 - accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2415 - accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2349 - accuracy: 0.9238\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2339 - accuracy: 0.9524\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2568 - accuracy: 0.9048\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2442 - accuracy: 0.9524\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2311 - accuracy: 0.9429\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2255 - accuracy: 0.9333\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2153 - accuracy: 0.9524\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.2130 - accuracy: 0.9524\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2250 - accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.2059 - accuracy: 0.9619\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2135 - accuracy: 0.9619\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2257 - accuracy: 0.9619\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2370 - accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2202 - accuracy: 0.9524\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2301 - accuracy: 0.9619\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2067 - accuracy: 0.9619\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1989 - accuracy: 0.9714\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1899 - accuracy: 0.9619\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1930 - accuracy: 0.9714\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1996 - accuracy: 0.9429\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1974 - accuracy: 0.9524\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.1994 - accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1901 - accuracy: 0.9524\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.1952 - accuracy: 0.9619\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.2105 - accuracy: 0.9238\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.1698 - accuracy: 0.9810\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.1631 - accuracy: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2232bdd4da0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = loss_fn,\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-school",
   "metadata": {},
   "source": [
    "### Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "instructional-range",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/sample - loss: 0.2461 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24613745808601378, 0.8888889]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-kennedy",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "military-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict([[5.4, 3. , 4.5, 1.5]])\n",
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-terrace",
   "metadata": {},
   "source": [
    "### 專家版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acceptable-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unsigned-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "numerical-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.3 2.9 5.6 1.8]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.  3.2 1.2 0.2]], shape=(32, 4), dtype=float64) tf.Tensor([2 1 0 2 0 2 1 1 0 0 2 1 2 2 1 0 1 2 1 1 1 1 0 0 1 0 1 0 2 0 2 0], shape=(32,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [7.9 3.8 6.4 2. ]], shape=(32, 4), dtype=float64) tf.Tensor([0 2 1 0 1 2 2 1 0 1 1 0 1 1 0 1 1 1 2 2 2 0 0 1 2 2 1 1 0 0 1 2], shape=(32,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[5.1 3.3 1.7 0.5]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.4 2.8 5.6 2.2]], shape=(32, 4), dtype=float64) tf.Tensor([0 0 1 0 2 0 2 1 0 0 2 0 2 0 2 0 2 2 1 0 2 0 1 1 1 0 1 0 1 1 1 2], shape=(32,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6.6 3.  4.4 1.4]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.2 4.1 1.5 0.1]], shape=(9, 4), dtype=float64) tf.Tensor([1 0 2 2 1 1 2 2 0], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for iris_data,iris_labels in train_ds:\n",
    "    print(iris_data,iris_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "assured-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128,activation = 'relu')\n",
    "        self.d2 = Dense(3)\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fleet-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "damaged-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=  'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss') \n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hired-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "\n",
    "def train_step(iris_data,iris_labels):\n",
    "    with tf.GradientTape() as tape:  #tf.GradientTape訓練模型\n",
    "        predictions = model(iris_data,training = True) #確認訓練來源\n",
    "        loss = loss_object(iris_labels,predictions) #建立Loss運算來源\n",
    "    gradients = tape.gradient(loss,model.trainable_variables) #\bbackward 反向傳播\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables)) #取得訓練的權重、偏移量優化\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(iris_labels,predictions)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "powered-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(iris_data,iris_labels):\n",
    "    predictions = model(iris_data,training = False) #training=False 表示測試資料進行測試\n",
    "    t_loss = loss_object(iris_labels,predictions) #建立Loss\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(iris_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bacterial-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 1, 訓練資料損失: 0.9533318281173706, 訓練資料準確率: 60.000003814697266, 測試資料損失: 0.9039729833602905, 測試資料準確率: 80.0\n",
      "迭代 2, 訓練資料損失: 0.89747154712677, 訓練資料準確率: 70.47618865966797, 測試資料損失: 0.8443271517753601, 測試資料準確率: 80.0\n",
      "迭代 3, 訓練資料損失: 0.8468695878982544, 訓練資料準確率: 74.28571319580078, 測試資料損失: 0.8006834387779236, 測試資料準確率: 86.66666412353516\n",
      "迭代 4, 訓練資料損失: 0.7985471487045288, 訓練資料準確率: 90.47618865966797, 測試資料損失: 0.7620534300804138, 測試資料準確率: 95.55555725097656\n",
      "迭代 5, 訓練資料損失: 0.7545279264450073, 訓練資料準確率: 96.19047546386719, 測試資料損失: 0.7223891019821167, 測試資料準確率: 95.55555725097656\n",
      "迭代 6, 訓練資料損失: 0.7150804400444031, 訓練資料準確率: 95.23809814453125, 測試資料損失: 0.6825802326202393, 測試資料準確率: 93.33333587646484\n",
      "迭代 7, 訓練資料損失: 0.6801405549049377, 訓練資料準確率: 93.33333587646484, 測試資料損失: 0.647443413734436, 測試資料準確率: 93.33333587646484\n",
      "迭代 8, 訓練資料損失: 0.6486801505088806, 訓練資料準確率: 93.33333587646484, 測試資料損失: 0.6193569898605347, 測試資料準確率: 93.33333587646484\n",
      "迭代 9, 訓練資料損失: 0.6199455261230469, 訓練資料準確率: 96.19047546386719, 測試資料損失: 0.59673011302948, 測試資料準確率: 95.55555725097656\n",
      "迭代 10, 訓練資料損失: 0.5941234827041626, 訓練資料準確率: 96.19047546386719, 測試資料損失: 0.5754052400588989, 測試資料準確率: 95.55555725097656\n",
      "迭代 11, 訓練資料損失: 0.5711179375648499, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.5540939569473267, 測試資料準確率: 95.55555725097656\n",
      "迭代 12, 訓練資料損失: 0.5505430698394775, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.5350859761238098, 測試資料準確率: 95.55555725097656\n",
      "迭代 13, 訓練資料損失: 0.532012939453125, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.5197986364364624, 測試資料準確率: 95.55555725097656\n",
      "迭代 14, 訓練資料損失: 0.5148321986198425, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.506783664226532, 測試資料準確率: 95.55555725097656\n",
      "迭代 15, 訓練資料損失: 0.498733788728714, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4937230348587036, 測試資料準確率: 95.55555725097656\n",
      "迭代 16, 訓練資料損失: 0.4836828410625458, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4804571866989136, 測試資料準確率: 95.55555725097656\n",
      "迭代 17, 訓練資料損失: 0.46966660022735596, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.46832275390625, 測試資料準確率: 95.55555725097656\n",
      "迭代 18, 訓練資料損失: 0.45657455921173096, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4580915570259094, 測試資料準確率: 95.55555725097656\n",
      "迭代 19, 訓練資料損失: 0.44418764114379883, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.44875991344451904, 測試資料準確率: 95.55555725097656\n",
      "迭代 20, 訓練資料損失: 0.43241122364997864, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.43950748443603516, 測試資料準確率: 97.77777862548828\n",
      "迭代 21, 訓練資料損失: 0.4212000072002411, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4302889108657837, 測試資料準確率: 97.77777862548828\n",
      "迭代 22, 訓練資料損失: 0.41052475571632385, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4213186204433441, 測試資料準確率: 97.77777862548828\n",
      "迭代 23, 訓練資料損失: 0.4003502428531647, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4131789207458496, 測試資料準確率: 97.77777862548828\n",
      "迭代 24, 訓練資料損失: 0.3905840516090393, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.4057714343070984, 測試資料準確率: 97.77777862548828\n",
      "迭代 25, 訓練資料損失: 0.3811449408531189, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.3985599875450134, 測試資料準確率: 97.77777862548828\n",
      "迭代 26, 訓練資料損失: 0.372021347284317, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.39124536514282227, 測試資料準確率: 97.77777862548828\n",
      "迭代 27, 訓練資料損失: 0.36323320865631104, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.384157657623291, 測試資料準確率: 97.77777862548828\n",
      "迭代 28, 訓練資料損失: 0.3547471761703491, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.37745076417922974, 測試資料準確率: 97.77777862548828\n",
      "迭代 29, 訓練資料損失: 0.34653759002685547, 訓練資料準確率: 97.14286041259766, 測試資料損失: 0.3712528944015503, 測試資料準確率: 97.77777862548828\n",
      "迭代 30, 訓練資料損失: 0.3385688364505768, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3652423620223999, 測試資料準確率: 97.77777862548828\n",
      "迭代 31, 訓練資料損失: 0.3308241367340088, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3590579330921173, 測試資料準確率: 97.77777862548828\n",
      "迭代 32, 訓練資料損失: 0.32328692078590393, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3526267111301422, 測試資料準確率: 97.77777862548828\n",
      "迭代 33, 訓練資料損失: 0.31602001190185547, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3466689884662628, 測試資料準確率: 97.77777862548828\n",
      "迭代 34, 訓練資料損失: 0.30898618698120117, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.34153637290000916, 測試資料準確率: 97.77777862548828\n",
      "迭代 35, 訓練資料損失: 0.30208855867385864, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.33643054962158203, 測試資料準確率: 97.77777862548828\n",
      "迭代 36, 訓練資料損失: 0.2953720688819885, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.331196665763855, 測試資料準確率: 97.77777862548828\n",
      "迭代 37, 訓練資料損失: 0.2888425886631012, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.32582321763038635, 測試資料準確率: 97.77777862548828\n",
      "迭代 38, 訓練資料損失: 0.28248968720436096, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3204936385154724, 測試資料準確率: 97.77777862548828\n",
      "迭代 39, 訓練資料損失: 0.27633172273635864, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.31559085845947266, 測試資料準確率: 97.77777862548828\n",
      "迭代 40, 訓練資料損失: 0.27035465836524963, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.31114041805267334, 測試資料準確率: 97.77777862548828\n",
      "迭代 41, 訓練資料損失: 0.26451075077056885, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.3067537248134613, 測試資料準確率: 95.55555725097656\n",
      "迭代 42, 訓練資料損失: 0.25878196954727173, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.30198442935943604, 測試資料準確率: 95.55555725097656\n",
      "迭代 43, 訓練資料損失: 0.2532304525375366, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.29717427492141724, 測試資料準確率: 97.77777862548828\n",
      "迭代 44, 訓練資料損失: 0.24787433445453644, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.2928832173347473, 測試資料準確率: 93.33333587646484\n",
      "迭代 45, 訓練資料損失: 0.2426764965057373, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.28903889656066895, 測試資料準確率: 93.33333587646484\n",
      "迭代 46, 訓練資料損失: 0.23755806684494019, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.28498369455337524, 測試資料準確率: 93.33333587646484\n",
      "迭代 47, 訓練資料損失: 0.2325897365808487, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.28083014488220215, 測試資料準確率: 93.33333587646484\n",
      "迭代 48, 訓練資料損失: 0.22778970003128052, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.2767828702926636, 測試資料準確率: 93.33333587646484\n",
      "迭代 49, 訓練資料損失: 0.2231246531009674, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.2729361355304718, 測試資料準確率: 93.33333587646484\n",
      "迭代 50, 訓練資料損失: 0.21860118210315704, 訓練資料準確率: 98.0952377319336, 測試資料損失: 0.2693527936935425, 測試資料準確率: 95.55555725097656\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "    for iris_data,iris_labels in train_ds:\n",
    "        train_step(iris_data,iris_labels)\n",
    "        \n",
    "    for test_iris_data,test_iris_labels in test_ds:\n",
    "        test_step(test_iris_data,test_iris_labels)\n",
    "        \n",
    "    template = '迭代 {}, 訓練資料損失: {}, 訓練資料準確率: {}, 測試資料損失: {}, 測試資料準確率: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-correlation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
